{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tGl44nusP9Cy"
   },
   "source": [
    "# Data Science Essentials: GeoPandas\n",
    "    Samuel Goldrup\n",
    "    Math 403\n",
    "    3 October 2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "17L4Fi8qab7J"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x000002F6AE4707F0>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed')': /simple/geopandas/\n",
      "WARNING: Retrying (Retry(total=3, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x000002F6AE470AF0>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed')': /simple/geopandas/\n",
      "WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x000002F6AE470DF0>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed')': /simple/geopandas/\n",
      "WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x000002F6AE470FA0>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed')': /simple/geopandas/\n",
      "WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x000002F6AE49B190>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed')': /simple/geopandas/\n",
      "ERROR: Could not find a version that satisfies the requirement geopandas (from versions: none)\n",
      "ERROR: No matching distribution found for geopandas\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_32596/1035204209.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m' pip install geopandas'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mfiles\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mgeopandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mgpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'google'"
     ]
    }
   ],
   "source": [
    "! pip install geopandas\n",
    "from google.colab import files\n",
    "import geopandas as gpd\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from shapely.geometry import Point, Polygon\n",
    "from matplotlib.colors import LogNorm\n",
    "from matplotlib.cm import ScalarMappable\n",
    "from matplotlib import animation\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "civIOQkeyMI2"
   },
   "source": [
    "## Problem 1\n",
    "\n",
    "Read in the file *airports.csv* as a pandas dataframe.\n",
    "Create three convex hulls around the three sets of airports listed below.\n",
    "This can be done by passing in lists of the airports' coordinates to a *shapely.geometry.Polygon* object.\n",
    "\n",
    "1. Maio Airport, Scatsta Airport, Stokmarknes Skagen Airport, Bekily Airport, K. D. Matanzima Airport, RAF Ascension Island\n",
    "2. Oiapoque Airport, Maio Airport, Zhezkazgan Airport, Walton Airport, RAF Ascension Island, Usiminas Airport, Piloto Osvaldo Marques Dias Airport\n",
    "3. Zhezkazgan Airport, Khanty Mansiysk Airport, Novy Urengoy Airport, Kalay Airport, Biju Patnaik Airport, Walton Airport\n",
    "\t\n",
    "Create a new GeoDataFrame with these three Polygons as entries.\n",
    "Plot this GeoDataFrame on top of an outlined world map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X7Q_kDhKbGQR"
   },
   "outputs": [],
   "source": [
    "# upload airport.csv\n",
    "airport = files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "34RGRyXmxoPQ"
   },
   "outputs": [],
   "source": [
    "first_set = ['Maio Airport', 'Scatsta Airport', 'Stokmarknes Skagen Airport',\n",
    "                 'Bekily Airport','K. D. Matanzima Airport', 'RAF Ascension Island']\n",
    "second_set = ['Oiapoque Airport','Maio Airport', 'Zhezkazgan Airport',\n",
    "                'Walton Airport','RAF Ascension Island','Usiminas Airport',\n",
    "                 'Piloto Osvaldo Marques Dias Airport']\n",
    "third_set = ['Zhezkazgan Airport','Khanty Mansiysk Airport','Novy Urengoy Airport',\n",
    "                 'Kalay Airport','Biju Patnaik Airport','Walton Airport']\n",
    "\n",
    "first_set = ['Maio Airport', 'Scatsta Airport', 'Stokmarknes Skagen Airport',\n",
    "                 'Bekily Airport','K. D. Matanzima Airport', 'RAF Ascension Island']\n",
    "second_set = ['Oiapoque Airport','Maio Airport', 'Zhezkazgan Airport',\n",
    "                'Walton Airport','RAF Ascension Island','Usiminas Airport',\n",
    "                 'Piloto Osvaldo Marques Dias Airport']\n",
    "third_set = ['Zhezkazgan Airport','Khanty Mansiysk Airport','Novy Urengoy Airport',\n",
    "                 'Kalay Airport','Biju Patnaik Airport','Walton Airport']\n",
    "\n",
    "airports = pd.read_csv('airports.csv')\n",
    "airports['Coordinates'] = list(zip(airports.Longitude,airports.Latitude))\n",
    "airports['Coordinates'] = airports.Coordinates.apply(Point)\n",
    "airports = gpd.GeoDataFrame(airports,geometry=\"Coordinates\")\n",
    "\n",
    "airports.set_index('Name',inplace=True)\n",
    "\n",
    "first = airports.loc[first_set]\n",
    "second = airports.loc[second_set]\n",
    "third = airports.loc[third_set]\n",
    "\n",
    "f = list(zip(first.Longitude, first.Latitude))\n",
    "s = list(zip(second.Longitude, second.Latitude))\n",
    "t = list(zip(third.Longitude, third.Latitude))\n",
    "\n",
    "f_poly = Polygon(f).convex_hull\n",
    "s_poly = Polygon(s).convex_hull\n",
    "t_poly = Polygon(t).convex_hull\n",
    "\n",
    "world = gpd.read_file(gpd.datasets.get_path('naturalearth_lowres'))\n",
    "\n",
    "fig,ax = plt.subplots(figsize=(10,7),ncols=1,nrows=1)\n",
    "base = world.boundary.plot(edgecolor='black', ax=ax, linewidth=1)\n",
    "\n",
    "frame = gpd.GeoDataFrame({'geometry':[f_poly,s_poly,t_poly]})\n",
    "frame.plot(ax=base)\n",
    "\n",
    "ax.set_xlabel('Longitude')\n",
    "ax.set_ylabel('Latitude')\n",
    "ax.set_title(\"World Airpots\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7aa-B6ZjPwNb"
   },
   "source": [
    "## Problem 2\n",
    "Use the command *geopandas.read_file('county_data.gpkg')* to create a GeoDataFrame of information about US counties.\n",
    "Each county's shape is stored in the *geometry* column.\n",
    "Use this to **plot the outlines of all US counties two times**, first using the default CRS and then using EPSG:5071.\n",
    "\n",
    "Next, create a new GeoDataFrame that combines all counties within a single state.\n",
    "Drop states with the following STATEFP codes: 02, 15, 60, 66, 69, 72, 78.\n",
    "Plot this GeoDataFrame to see an outline of the 48 contiguous states.\n",
    "Ensure a CRS of 5071."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QrfBpqXqydm9"
   },
   "outputs": [],
   "source": [
    "# upload county.gpkg.zip\n",
    "county = files.upload()\n",
    "!unzip county_data.gpkg.zip\n",
    "county_df = gpd.read_file('county_data.gpkg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_xKwSRuy5OgE"
   },
   "outputs": [],
   "source": [
    "county_df[\"geometry\"].plot()\n",
    "plt.show()\n",
    "\n",
    "county_df.to_crs(5071,inplace=True)\n",
    "\n",
    "county_df[\"geometry\"].plot()\n",
    "plt.show()\n",
    "\n",
    "county_df.set_index('STATEFP',drop=True,inplace=True)\n",
    "county_df.drop(index=['02','15','60','66','69','72','78'],inplace=True)\n",
    "county_df = county_df.dissolve(by=\"STATEFP\")\n",
    "county_df.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JlBqcl1EPyFA"
   },
   "source": [
    "## Problem 3\n",
    "\n",
    "Load in the file *nytimes.csv* as a DataFrame.\n",
    "This file includes county-level data for the cumulative cases and deaths of Covid-19 in the US, starting with the first case in Snohomish County, Washington, on January 21, 2020.\n",
    "**First, convert the *date* column into a *DatetimeIndex*.**\n",
    "\n",
    "Next, use county FIPS codes to **merge your GeoDataFrame from the previous problem with the DataFrame you just created.**\n",
    "A FIPS code is a 5-digit unique identifier for geographic locations.\n",
    "For this lab, we will ignore rows in the Covid-19 DataFramw tih unknown FIPS codes.\n",
    "Also, we will just be examining data from the contiguous US, so **drop all data from Hawaii and Alaska.**\n",
    "\n",
    "Note that the *fips* column of the Covid-19 DataFrame stores entries as floats, but the county GeoDataFrame stores FIPS codes as strings, with the first two digits in the *STATEFP* column and the last three in the *COUNTYFP* column.\n",
    "\n",
    "**Plot the cases from March 21, 2020 on top of your state outline map from the previous problem.\n",
    "Finally, print out the name of the county with the most cases along with its case count.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K-uqSOSV13Z3"
   },
   "outputs": [],
   "source": [
    "nytimes = files.upload()\n",
    "nytimes = pd.read_csv(\"nytimes.csv\",index_col=0)\n",
    "nytimes['date'] = pd.to_datetime(nytimes['date'])\n",
    "\n",
    "data = gpd.read_file('county_data.gpkg')\n",
    "data['fips'] = (data['STATEFP'] + data['COUNTYFP']).astype(float)\n",
    "data.set_index('STATEFP',drop=True,inplace=True)\n",
    "data.drop(['02','15','60','66','69','72','78'],inplace=True)\n",
    "merged = data.merge(nytimes,on='fips')\n",
    "#merged.set_index('STATEFP',drop=True,inplace=True)\n",
    "#merged.drop(index=['02','15','60','66','69','72','78'],inplace=True)\n",
    "fig, ax = plt.subplots(1, figsize=(10,4))\n",
    "#data.set_index('STATEFP',drop=True,inplace=True)\n",
    "base = data.dissolve(by='STATEFP').boundary.plot(color='black',ax=ax)\n",
    "gdf[gdf['date'] == '2020-03-31'].plot(ax=base,column='cases',cmap=\"viridis_r\")\n",
    "plt.show()\n",
    "poo = gdf[gdf['date'] == '2020-03-21']\n",
    "poo.set_index('county',inplace=True)\n",
    "idx = poo['cases'].idxmax()\n",
    "print(idx, poo.loc['New York City']['cases'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q03e2ANSPzlI"
   },
   "source": [
    "## Problem 4\n",
    "\n",
    "As in Problem 3, plot your state outline map together with a map of Covid-19 cases from March 21, 2020.\n",
    "This time, use a log scale.\n",
    "Use EPSG:5071.\n",
    "Pick a good colormap and be sure to display a colorbar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NRyJ4klbZK1C"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15,6), ncols=1, nrows=1)\n",
    "base = data.dissolve(by='STATEFP').boundary.plot(color='black',ax=ax)\n",
    "\n",
    "data = gdf[gdf['date'] == '2020-03-31']['cases']\n",
    "norm = LogNorm(vmin=min(data),vmax=max(data))\n",
    "\n",
    "gdf[gdf['date'] == '2020-03-21'].plot(ax=ax, column='cases',cmap='viridis_r',edgecolor='gray',norm=norm)\n",
    "cbar = fig.colorbar(ScalarMappable(norm=norm, cmap='viridis_r'), ax=ax, orientation='horizontal', pad=0, label='CASES')\n",
    "\n",
    "ax.set_title('County Cases on Log Scale')\n",
    "ax.set_yticks([])\n",
    "ax.set_xticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TwcaLc6xP1Hm"
   },
   "source": [
    "## Problem 5\n",
    "In this problem, you will create an animation of the spread of Covid-19 through US counties from January 21, 2020 to June 21, 2020.\n",
    "Use a log scale and a good colormap, and be sure that you're using the same norm and colorbar for the whole animation.\n",
    "Use EPSG:5071 for the CRS.\n",
    "\n",
    "As a reminder, below is a summary of what you will need in order to animate this map.\n",
    "You may also find it helpful to refer to the animation section included with the Volume 4 lab manual. \n",
    "\n",
    "- Set up your figure and norm. Be sure to use the highest case count for your vmax so that the scale remains uniform.\n",
    "- Write your update function. This should plot the cases from a given day.\n",
    "- Set up your colorbar. Do this outside the update function to avoid adding a new colorbar each day.\n",
    "- Create the animation. Check to make sure everything displays properly before you save it.\n",
    "- Save the animation.\n",
    "- Display the animation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l5ld8pKKZwwG"
   },
   "outputs": [],
   "source": [
    "#Set up figure and norm\n",
    "\n",
    "def update(date):\n",
    "    #Plot the cases from a single day\n",
    "    pass\n",
    "    \n",
    "#Set up the colorbar\n",
    "\n",
    "#Create the animation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U2-FaJ3-lUku"
   },
   "outputs": [],
   "source": [
    "#Save the animation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ezDGH5QUab7i"
   },
   "source": [
    "<video src='your_video_name.mp4' controls width=800>"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "pandas4_colab.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
